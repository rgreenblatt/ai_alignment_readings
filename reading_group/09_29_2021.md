# Bitter lesson
 - [http://www.incompleteideas.net/IncIdeas/BitterLesson.html](http://www.incompleteideas.net/IncIdeas/BitterLesson.html)
 - Do we think AIs designed by AGIs will likely obey this rule? In other
   words, is computation so effective because of the limitations of design for
   humans minds?
 - How does this square with considerable algorithmic improvements in Deep
   Learning (~44x based on [ai and efficiency](https://openai.com/blog/ai-and-efficiency/)).
 - What does this imply about timelines? Computational overhang?
 - Any strong counter arguments?
 - This doesn't seem to hold in domains like solvers, optimizers and similar.
   For example, we have seen massive improvements in SAT solvers via complex but
   human understandable algorithms.
 - Likely future related topics: scaling laws, 
  [deep learning compute over time](https://openai.com/blog/ai-and-efficiency/),
  [deep learning efficiency over time](https://openai.com/blog/ai-and-efficiency/)

# Prosaic AI alignment
 - [https://ai-alignment.com/prosaic-ai-control-b959644d79c2](https://ai-alignment.com/prosaic-ai-control-b959644d79c2)
 - Thoughts on feasibility of prosaic alignment?
 - How can we test the hypothesis that prosaic alignment is impossible (or at least nearly impossible for humans)?
   - How useful is prosaic alignment research in the world where prosaic alignment is nearly impossible?

# Most important century series
 - [https://www.cold-takes.com/most-important-century/](https://www.cold-takes.com/most-important-century/)
 - Has anyone read Age of Em? (mostly out of curiosity)
 - Do we need to worry about digital people alignment? What would this even mean?
 - What do you think about timelines?
 - Better approaches than bio anchors?
 - How does the idea of a computational overhang square with the bio anchors approach? 
 - Important flaws in the argument?
